{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Tag Recommendation System - Data Preparation\n",
    "\n",
    "This notebook prepares filtered data from BSD10k metadata by:\n",
    "\n",
    "1. Loading and filtering the BSD10k metadata\n",
    "2. Filtering tags to match the valid RankST tagset\n",
    "3. Keeping only sounds with 5-15 tags\n",
    "4. Creating input/ground truth pairs for evaluation\n",
    "5. Creating a CLAP-specific tagset from filtered data\n",
    "6. Outputting filtered data to CSV\n",
    "\n",
    "## Data Preparation Steps:\n",
    "- Filter sounds with sound_id > 207648\n",
    "- Keep only tags that match tagset_rankst.txt\n",
    "- Keep only sounds with 5-15 tags\n",
    "- Save filtered data to data/BSD10k/BSD10K_metadata_filtered.csv\n",
    "- Create input/ground truth pairs for evaluation\n",
    "- Create tagset_clap.txt containing only tags present in filtered data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import List, Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the RankST tagset (valid tags)\n",
    "print(\"Loading valid tagset...\")\n",
    "with open('data/tagset_rankst.txt', 'r') as f:\n",
    "    valid_tags = set(tag.strip() for tag in f.readlines())\n",
    "\n",
    "print(f\"Loaded {len(valid_tags)} valid tags\")\n",
    "print(f\"First 10 tags: {list(valid_tags)[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BSD10k metadata\n",
    "print(\"Loading BSD10k metadata...\")\n",
    "metadata_df = pd.read_csv('data/BSD10k/BSD10k_metadata.csv')\n",
    "print(f\"Original dataset size: {len(metadata_df)} sounds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter sounds with sound_id > 207648\n",
    "print(\"Filtering sounds with sound_id > 207648...\")\n",
    "filtered_df = metadata_df[metadata_df['sound_id'] > 207648].copy()\n",
    "print(f\"After sound_id filter: {len(filtered_df)} sounds\")\n",
    "\n",
    "print(f\"Sound ID range: {filtered_df['sound_id'].min()} - {filtered_df['sound_id'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_filter_tags(tags_str: str, valid_tags: set) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parse tags string and filter to keep only valid tags\n",
    "    \"\"\"\n",
    "    if pd.isna(tags_str):\n",
    "        return []\n",
    "    \n",
    "    # Split tags by comma and clean them\n",
    "    tags = [tag.strip() for tag in tags_str.split(',')]\n",
    "    \n",
    "    # Filter to keep only valid tags\n",
    "    valid_sound_tags = [tag for tag in tags if tag in valid_tags]\n",
    "    \n",
    "    return valid_sound_tags\n",
    "\n",
    "# Apply tag filtering\n",
    "print(\"Parsing and filtering tags...\")\n",
    "filtered_df['valid_tags'] = filtered_df['tags'].apply(lambda x: parse_and_filter_tags(x, valid_tags))\n",
    "filtered_df['num_valid_tags'] = filtered_df['valid_tags'].apply(len)\n",
    "\n",
    "print(f\"Valid tags per sound: min={filtered_df['num_valid_tags'].min()}, max={filtered_df['num_valid_tags'].max()}, mean={filtered_df['num_valid_tags'].mean():.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to keep only sounds with 5-15 valid tags\n",
    "print(\"Filtering sounds with 5-15 valid tags...\")\n",
    "final_df = filtered_df[(filtered_df['num_valid_tags'] >= 5) & (filtered_df['num_valid_tags'] <= 15)].copy()\n",
    "print(f\"After tag count filter: {len(final_df)} sounds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert valid_tags list to comma-separated string for CSV output\n",
    "final_df['valid_tags_str'] = final_df['valid_tags'].apply(lambda x: ','.join(x))\n",
    "\n",
    "# Select and reorder columns for output\n",
    "output_columns = ['sound_id', 'title', 'valid_tags_str', 'num_valid_tags']\n",
    "output_df = final_df[output_columns].copy()\n",
    "\n",
    "# Rename columns for clarity\n",
    "output_df.columns = ['sound_id', 'title', 'tags', 'num_tags']\n",
    "\n",
    "# Create data/BSD10k directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('data/BSD10k', exist_ok=True)\n",
    "\n",
    "# Save to CSV in data/BSD10k folder\n",
    "output_file = 'data/BSD10k/BSD10K_metadata_filtered.csv'\n",
    "output_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nFiltered data saved to {output_file}\")\n",
    "print(f\"Total sounds in filtered dataset: {len(output_df)}\")\n",
    "print(f\"Average number of tags per sound: {output_df['num_tags'].mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some statistics about the filtered dataset\n",
    "print(\"Dataset Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total sounds: {len(output_df)}\")\n",
    "print(f\"Min tags per sound: {output_df['num_tags'].min()}\")\n",
    "print(f\"Max tags per sound: {output_df['num_tags'].max()}\")\n",
    "print(f\"Mean tags per sound: {output_df['num_tags'].mean():.2f}\")\n",
    "print(f\"Median tags per sound: {output_df['num_tags'].median():.2f}\")\n",
    "\n",
    "# Display first few rows of the filtered dataset\n",
    "print(\"\\nFirst 5 rows of filtered dataset:\")\n",
    "print(\"-\" * 50)\n",
    "display(output_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_ground_truth_pairs(sound_data: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    For each sound, randomly select 3 tags as input and use remaining as ground truth\n",
    "    \"\"\"\n",
    "    test_data = []\n",
    "    \n",
    "    for _, row in sound_data.iterrows():\n",
    "        tags = row['valid_tags']\n",
    "        sound_id = row['sound_id']\n",
    "        \n",
    "        # Randomly shuffle tags\n",
    "        shuffled_tags = tags.copy()\n",
    "        random.shuffle(shuffled_tags)\n",
    "        \n",
    "        # Select 3 tags as input, rest as ground truth\n",
    "        input_tags = shuffled_tags[:3]\n",
    "        ground_truth_tags = shuffled_tags[3:]\n",
    "        \n",
    "        test_data.append({\n",
    "            'sound_id': sound_id,\n",
    "            'input_tags': input_tags,\n",
    "            'ground_truth_tags': ground_truth_tags,\n",
    "            'total_tags': len(tags),\n",
    "            'title': row['title']\n",
    "        })\n",
    "    \n",
    "    return test_data\n",
    "\n",
    "# Create input/ground truth pairs\n",
    "print(\"Creating input/ground truth pairs...\")\n",
    "test_data = create_input_ground_truth_pairs(final_df)\n",
    "\n",
    "print(f\"Created {len(test_data)} test cases\")\n",
    "print(f\"Average ground truth tags per sound: {np.mean([len(item['ground_truth_tags']) for item in test_data]):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some examples of the test data\n",
    "print(\"Examples of test cases:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, case in enumerate(test_data[:5]):\n",
    "    print(f\"\\nTest case {i+1}:\")\n",
    "    print(f\"  Sound ID: {case['sound_id']}\")\n",
    "    print(f\"  Title: {case['title']}\")\n",
    "    print(f\"  Input tags ({len(case['input_tags'])}): {case['input_tags']}\")\n",
    "    print(f\"  Ground truth tags ({len(case['ground_truth_tags'])}): {case['ground_truth_tags']}\")\n",
    "    print(f\"  Total tags: {case['total_tags']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataset statistics for input/ground truth pairs\n",
    "gt_counts = [len(case['ground_truth_tags']) for case in test_data]\n",
    "total_counts = [case['total_tags'] for case in test_data]\n",
    "\n",
    "print(\"Input/Ground Truth Dataset Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total test cases: {len(test_data)}\")\n",
    "print(f\"Min ground truth tags: {min(gt_counts)}\")\n",
    "print(f\"Max ground truth tags: {max(gt_counts)}\")\n",
    "print(f\"Mean ground truth tags: {np.mean(gt_counts):.2f}\")\n",
    "print(f\"Median ground truth tags: {np.median(gt_counts):.2f}\")\n",
    "print()\n",
    "print(f\"Min total tags: {min(total_counts)}\")\n",
    "print(f\"Max total tags: {max(total_counts)}\")\n",
    "print(f\"Mean total tags: {np.mean(total_counts):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the input/ground truth pairs for use with the tag recommendation system\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Save as pickle for easy loading\n",
    "pickle_file = 'data/input_ground_truth_pairs.pkl'\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(test_data, f)\n",
    "\n",
    "# Also save as JSON for human readability\n",
    "json_file = 'data/input_ground_truth_pairs.json'\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(test_data, f, indent=2)\n",
    "\n",
    "print(f\"Input/Ground truth pairs saved to:\")\n",
    "print(f\"- {pickle_file} ({len(test_data)} test cases)\")\n",
    "print(f\"- {json_file} ({len(test_data)} test cases)\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary = {\n",
    "    'total_test_cases': len(test_data),\n",
    "    'avg_ground_truth_tags': np.mean(gt_counts),\n",
    "    'avg_total_tags': np.mean(total_counts),\n",
    "    'min_ground_truth_tags': min(gt_counts),\n",
    "    'max_ground_truth_tags': max(gt_counts),\n",
    "    'sounds_filtered': {\n",
    "        'original_count': len(metadata_df),\n",
    "        'after_sound_id_filter': len(filtered_df),\n",
    "        'after_tag_count_filter': len(final_df)\n",
    "    },\n",
    "    'tagsets': {\n",
    "        'rankst_tagset_size': len(valid_tags),\n",
    "        'clap_tagset_size': len(clap_tagset),\n",
    "        'tags_removed_for_clap': len(valid_tags) - len(clap_tagset)\n",
    "    }\n",
    "}\n",
    "\n",
    "summary_file = 'data/input_ground_truth_summary.json'\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nSummary saved to {summary_file}\")\n",
    "print(\"Data preparation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CLAP tagset by filtering RankST tagset to only include tags present in filtered data\n",
    "print(\"Creating CLAP tagset from filtered data...\")\n",
    "\n",
    "# Extract all unique tags from the filtered dataset\n",
    "all_tags_in_filtered_data = set()\n",
    "for tags_list in final_df['valid_tags']:\n",
    "    all_tags_in_filtered_data.update(tags_list)\n",
    "\n",
    "print(f\"Total unique tags in filtered dataset: {len(all_tags_in_filtered_data)}\")\n",
    "\n",
    "# Filter RankST tagset to only include tags present in filtered data\n",
    "clap_tagset = valid_tags.intersection(all_tags_in_filtered_data)\n",
    "\n",
    "print(f\"Original RankST tagset size: {len(valid_tags)}\")\n",
    "print(f\"CLAP tagset size (tags present in filtered data): {len(clap_tagset)}\")\n",
    "print(f\"Removed {len(valid_tags) - len(clap_tagset)} tags not present in filtered data\")\n",
    "\n",
    "# Save CLAP tagset to file\n",
    "clap_tagset_file = 'data/tagset_clap.txt'\n",
    "with open(clap_tagset_file, 'w') as f:\n",
    "    for tag in sorted(clap_tagset):\n",
    "        f.write(f\"{tag}\\n\")\n",
    "\n",
    "print(f\"\\nCLAP tagset saved to {clap_tagset_file}\")\n",
    "print(f\"CLAP tagset contains {len(clap_tagset)} tags\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
