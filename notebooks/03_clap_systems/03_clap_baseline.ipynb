{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# CLAP Zero-Shot Tag Recommendation System\n",
        "\n",
        "This notebook implements a zero-shot tag recommendation system using LAION-CLAP embeddings.\n",
        "It recommends top 10 tags for each audio clip by computing cosine similarity between audio embeddings and text embeddings of tag descriptions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import laion_clap\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load input/ground truth pairs\n",
        "with open('data/input_ground_truth_pairs.json', 'r') as f:\n",
        "    input_gt_pairs = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(input_gt_pairs)} sound clips with input/ground truth pairs\")\n",
        "print(f\"Example entry: {input_gt_pairs[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load metadata\n",
        "metadata_df = pd.read_csv('data/BSD10k/BSD10K_metadata_filtered.csv')\n",
        "print(f\"Loaded metadata for {len(metadata_df)} sound clips\")\n",
        "print(metadata_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load tagset\n",
        "with open('data/tagset_clap_normalized_hyphen_unique.txt', 'r') as f:\n",
        "    clap_tags = [line.strip() for line in f.readlines()]\n",
        "\n",
        "print(f\"Loaded {len(clap_tags)} unique CLAP tags\")\n",
        "print(f\"First 10 tags: {clap_tags[:10]}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Initialize CLAP Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize CLAP model for text encoding\n",
        "model = laion_clap.CLAP_Module(enable_fusion=False)\n",
        "model.load_ckpt()  # Load default pretrained weights\n",
        "\n",
        "print(\"CLAP model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Create Text Embeddings for Tags\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tag_sentences(tag):\n",
        "    \"\"\"\n",
        "    Create 4 sentence variants for each tag:\n",
        "    - \"{Tag}.\" (first letter capitalized)\n",
        "    - \"The sound of {tag}.\"\n",
        "    - \"A recording of {tag}.\"\n",
        "    - \"An audio clip of {tag}.\"\n",
        "    \"\"\"\n",
        "    capitalized_tag = tag.capitalize()\n",
        "    sentences = [\n",
        "        f\"{capitalized_tag}.\",\n",
        "        f\"The sound of {tag}.\",\n",
        "        f\"A recording of {tag}.\",\n",
        "        f\"An audio clip of {tag}.\"\n",
        "    ]\n",
        "    return sentences\n",
        "\n",
        "# Test the function\n",
        "test_tag = \"guitar\"\n",
        "test_sentences = create_tag_sentences(test_tag)\n",
        "print(f\"Example sentences for '{test_tag}':\")\n",
        "for i, sentence in enumerate(test_sentences, 1):\n",
        "    print(f\"{i}. {sentence}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create text embeddings for all tags\n",
        "print(\"Creating text embeddings for all tags...\")\n",
        "\n",
        "tag_embeddings = {}\n",
        "batch_size = 32  # Process tags in batches for efficiency\n",
        "\n",
        "for i in tqdm(range(0, len(clap_tags), batch_size)):\n",
        "    batch_tags = clap_tags[i:i+batch_size]\n",
        "    \n",
        "    # Create sentences for all tags in the batch\n",
        "    all_sentences = []\n",
        "    tag_to_sentences_map = {}\n",
        "    \n",
        "    for tag in batch_tags:\n",
        "        sentences = create_tag_sentences(tag)\n",
        "        start_idx = len(all_sentences)\n",
        "        all_sentences.extend(sentences)\n",
        "        tag_to_sentences_map[tag] = list(range(start_idx, start_idx + 4))\n",
        "    \n",
        "    # Get embeddings for all sentences in the batch\n",
        "    with torch.no_grad():\n",
        "        text_embed = model.get_text_embedding(all_sentences)\n",
        "    \n",
        "    # Store embeddings for each tag (keep all 4 variants)\n",
        "    for tag in batch_tags:\n",
        "        indices = tag_to_sentences_map[tag]\n",
        "        tag_embeddings[tag] = text_embed[indices]\n",
        "\n",
        "print(f\"Created text embeddings for {len(tag_embeddings)} tags\")\n",
        "print(f\"Each tag has {len(list(tag_embeddings.values())[0])} sentence variants\")\n",
        "print(f\"Embedding dimension: {list(tag_embeddings.values())[0].shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_tag_embeddings(tag_embeddings, save_dir, filename_suffix=\"\"):\n",
        "    \"\"\"\n",
        "    Save all tag embeddings to disk in a single file.\n",
        "    \n",
        "    Args:\n",
        "        tag_embeddings (dict): Dictionary with tag names as keys and embeddings as values\n",
        "        save_dir (str or Path): Directory to save the embeddings\n",
        "        filename_suffix (str): Suffix to add to filenames for differentiation\n",
        "    \"\"\"\n",
        "    save_dir = Path(save_dir)\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    print(f\"Saving tag embeddings to {save_dir}...\")\n",
        "    \n",
        "    # Prepare data for saving\n",
        "    tags_list = list(tag_embeddings.keys())\n",
        "    embeddings_list = []\n",
        "    \n",
        "    for tag in tqdm(tags_list, desc=\"Preparing tag embeddings\"):\n",
        "        embeddings = tag_embeddings[tag]\n",
        "        \n",
        "        # Convert to numpy array if it's a torch tensor\n",
        "        if hasattr(embeddings, 'detach'):\n",
        "            embeddings_np = embeddings.detach().cpu().numpy()\n",
        "        else:\n",
        "            embeddings_np = embeddings\n",
        "        \n",
        "        embeddings_list.append(embeddings_np)\n",
        "    \n",
        "    # Stack all embeddings into a single array\n",
        "    # Shape: (num_tags, num_sentence_variants, embedding_dim)\n",
        "    all_embeddings = np.stack(embeddings_list, axis=0)\n",
        "    \n",
        "    # Save embeddings and tag list\n",
        "    embeddings_path = save_dir / f'tag_embeddings{filename_suffix}.npy'\n",
        "    tags_path = save_dir / f'tag_names{filename_suffix}.json'\n",
        "    \n",
        "    np.save(embeddings_path, all_embeddings)\n",
        "    \n",
        "    with open(tags_path, 'w') as f:\n",
        "        json.dump(tags_list, f, indent=2)\n",
        "    \n",
        "    print(f\"Saved {len(tag_embeddings)} tag embeddings to {embeddings_path}\")\n",
        "    print(f\"Saved tag names to {tags_path}\")\n",
        "    print(f\"Embeddings shape: {all_embeddings.shape}\")\n",
        "    \n",
        "    # Save a metadata file with tag information\n",
        "    metadata = {\n",
        "        'num_tags': len(tag_embeddings),\n",
        "        'embedding_dimension': all_embeddings.shape[2],\n",
        "        'num_sentence_variants': all_embeddings.shape[1],\n",
        "        'embeddings_shape': list(all_embeddings.shape),\n",
        "        'normalization': 'hyphen-normalized',\n",
        "        'files': {\n",
        "            'embeddings': f'tag_embeddings{filename_suffix}.npy',\n",
        "            'tag_names': f'tag_names{filename_suffix}.json'\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    metadata_path = save_dir / f'metadata{filename_suffix}.json'\n",
        "    with open(metadata_path, 'w') as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "    \n",
        "    print(f\"Saved metadata to {metadata_path}\")\n",
        "\n",
        "# Save the tag embeddings (hyphen-normalized version)\n",
        "tags_embeddings_dir = 'data/BSD10k/embeddings/tags'\n",
        "save_tag_embeddings(tag_embeddings, tags_embeddings_dir, filename_suffix=\"_hyphen\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Load Audio Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check available audio embeddings\n",
        "embeddings_dir = Path('data/BSD10k/embeddings/clap')\n",
        "available_embeddings = set([int(f.stem) for f in embeddings_dir.glob('*.npy')])\n",
        "\n",
        "print(f\"Found {len(available_embeddings)} audio embeddings\")\n",
        "\n",
        "# Filter input_gt_pairs to only include clips with available embeddings\n",
        "filtered_pairs = [pair for pair in input_gt_pairs if pair['sound_id'] in available_embeddings]\n",
        "\n",
        "print(f\"Using {len(filtered_pairs)} clips with both ground truth and audio embeddings\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load audio embeddings for the filtered clips\n",
        "print(\"Loading audio embeddings...\")\n",
        "\n",
        "audio_embeddings = {}\n",
        "\n",
        "for pair in tqdm(filtered_pairs):\n",
        "    sound_id = pair['sound_id']\n",
        "    embedding_path = embeddings_dir / f\"{sound_id}.npy\"\n",
        "    \n",
        "    if embedding_path.exists():\n",
        "        audio_embeddings[sound_id] = np.load(embedding_path)\n",
        "\n",
        "print(f\"Loaded audio embeddings for {len(audio_embeddings)} sound clips\")\n",
        "if audio_embeddings:\n",
        "    sample_embedding = list(audio_embeddings.values())[0]\n",
        "    print(f\"Audio embedding dimension: {sample_embedding.shape}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Compute Recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_tag_recommendations(audio_embedding, tag_embeddings, top_k=10):\n",
        "    \"\"\"\n",
        "    Get top-k tag recommendations for a given audio embedding.\n",
        "    For each tag, we take the maximum similarity among its 4 sentence variants.\n",
        "    \"\"\"\n",
        "    tag_similarities = {}\n",
        "    \n",
        "    for tag, text_embeds in tag_embeddings.items():\n",
        "        # Compute cosine similarity between audio and all text variants\n",
        "        similarities = cosine_similarity([audio_embedding], text_embeds)[0]\n",
        "        # Take the maximum similarity among the 4 variants\n",
        "        tag_similarities[tag] = np.max(similarities)\n",
        "    \n",
        "    # Sort tags by similarity and get top-k\n",
        "    sorted_tags = sorted(tag_similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_tags = [tag for tag, _ in sorted_tags[:top_k]]\n",
        "    top_scores = [score for _, score in sorted_tags[:top_k]]\n",
        "    \n",
        "    return top_tags, top_scores\n",
        "\n",
        "# Test the function\n",
        "test_sound_id = filtered_pairs[0]['sound_id']\n",
        "test_audio_embedding = audio_embeddings[test_sound_id]\n",
        "test_recommendations, test_scores = get_tag_recommendations(test_audio_embedding, tag_embeddings, top_k=5)\n",
        "\n",
        "print(f\"Test recommendations for sound {test_sound_id}:\")\n",
        "for i, (tag, score) in enumerate(zip(test_recommendations, test_scores), 1):\n",
        "    print(f\"{i}. {tag} (similarity: {score:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate recommendations for all clips\n",
        "print(\"Generating recommendations for all clips...\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for pair in tqdm(filtered_pairs):\n",
        "    sound_id = pair['sound_id']\n",
        "    \n",
        "    if sound_id not in audio_embeddings:\n",
        "        continue\n",
        "    \n",
        "    # Get audio embedding\n",
        "    audio_embedding = audio_embeddings[sound_id]\n",
        "    \n",
        "    # Get top 10 recommendations\n",
        "    predicted_tags, prediction_scores = get_tag_recommendations(\n",
        "        audio_embedding, tag_embeddings, top_k=10\n",
        "    )\n",
        "    \n",
        "    # Normalize ground truth tags to lowercase for comparison\n",
        "    ground_truth_tags = [tag.lower() for tag in pair['ground_truth_tags']]\n",
        "    predicted_tags_lower = [tag.lower() for tag in predicted_tags]\n",
        "    \n",
        "    # Calculate hits (intersection of predicted and ground truth)\n",
        "    hits = list(set(predicted_tags_lower) & set(ground_truth_tags))\n",
        "    \n",
        "    # Calculate metrics\n",
        "    precision = len(hits) / 10.0\n",
        "    recall = len(hits) / len(ground_truth_tags) if ground_truth_tags else 0.0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "    \n",
        "    result = {\n",
        "        'sound_id': sound_id,\n",
        "        'title': pair['title'],\n",
        "        'ground_truth_tags': ground_truth_tags,\n",
        "        'predicted_tags': predicted_tags,\n",
        "        'prediction_scores': prediction_scores,\n",
        "        'hits': hits,\n",
        "        'num_hits': len(hits),\n",
        "        'precision_at_10': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1\n",
        "    }\n",
        "    \n",
        "    results.append(result)\n",
        "\n",
        "print(f\"Generated recommendations for {len(results)} clips\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Evaluation and Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate overall metrics\n",
        "total_hits = sum(result['num_hits'] for result in results)\n",
        "total_predictions = len(results) * 10\n",
        "total_ground_truth = sum(len(result['ground_truth_tags']) for result in results)\n",
        "\n",
        "avg_precision_at_10 = np.mean([result['precision_at_10'] for result in results])\n",
        "avg_recall = np.mean([result['recall'] for result in results])\n",
        "avg_hits_per_clip = np.mean([result['num_hits'] for result in results])\n",
        "\n",
        "# Calculate F1 scores\n",
        "overall_precision = total_hits / total_predictions\n",
        "overall_recall = total_hits / total_ground_truth\n",
        "overall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
        "\n",
        "# Calculate average F1 score per clip\n",
        "f1_scores = []\n",
        "for result in results:\n",
        "    precision = result['precision_at_10']\n",
        "    recall = result['recall']\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    f1_scores.append(f1)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(\"=== CLAP Zero-Shot Tag Recommendation Results ===\")\n",
        "print(f\"Number of clips evaluated: {len(results)}\")\n",
        "print(f\"Total hits: {total_hits}\")\n",
        "print(f\"Total predictions: {total_predictions}\")\n",
        "print(f\"Total ground truth tags: {total_ground_truth}\")\n",
        "print()\n",
        "print(f\"Average Precision@10: {avg_precision_at_10:.4f}\")\n",
        "print(f\"Average Recall: {avg_recall:.4f}\")\n",
        "print(f\"Average F1 Score: {avg_f1:.4f}\")\n",
        "print(f\"Average hits per clip: {avg_hits_per_clip:.2f}\")\n",
        "print()\n",
        "print(f\"Overall Precision: {overall_precision:.4f}\")\n",
        "print(f\"Overall Recall: {overall_recall:.4f}\")\n",
        "print(f\"Overall F1 Score: {overall_f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show some example results\n",
        "print(\"=== Example Results ===\")\n",
        "\n",
        "# Sort by number of hits (best first)\n",
        "results_sorted = sorted(results, key=lambda x: x['num_hits'], reverse=True)\n",
        "\n",
        "for i, result in enumerate(results_sorted[:5]):\n",
        "    print(f\"\\n--- Example {i+1} (Sound ID: {result['sound_id']}) ---\")\n",
        "    print(f\"Title: {result['title']}\")\n",
        "    print(f\"Ground Truth Tags: {result['ground_truth_tags']}\")\n",
        "    print(f\"Predicted Tags: {result['predicted_tags']}\")\n",
        "    print(f\"Hits: {result['hits']} ({result['num_hits']} hits)\")\n",
        "    print(f\"Precision@10: {result['precision_at_10']:.3f}, Recall: {result['recall']:.3f}, F1: {result['f1_score']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution of hits\n",
        "hits_distribution = {}\n",
        "for result in results:\n",
        "    num_hits = result['num_hits']\n",
        "    hits_distribution[num_hits] = hits_distribution.get(num_hits, 0) + 1\n",
        "\n",
        "print(\"\\n=== Distribution of Hits ===\")\n",
        "for hits in sorted(hits_distribution.keys()):\n",
        "    count = hits_distribution[hits]\n",
        "    percentage = count / len(results) * 100\n",
        "    print(f\"{hits} hits: {count} clips ({percentage:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert numpy values to Python types for JSON serialization\n",
        "def convert_numpy_types(obj):\n",
        "    \"\"\"Recursively convert numpy types to Python types\"\"\"\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif isinstance(obj, dict):\n",
        "        return {key: convert_numpy_types(value) for key, value in obj.items()}\n",
        "    elif isinstance(obj, list):\n",
        "        return [convert_numpy_types(item) for item in obj]\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "# Convert results to be JSON serializable\n",
        "json_safe_results = convert_numpy_types(results)\n",
        "\n",
        "# Save results\n",
        "output_file = 'eval/clap_baseline_results.json'\n",
        "os.makedirs('eval', exist_ok=True)\n",
        "\n",
        "# Prepare summary\n",
        "summary = {\n",
        "    'model': 'CLAP Zero-Shot',\n",
        "    'num_clips': len(results),\n",
        "    'total_hits': int(total_hits),\n",
        "    'total_predictions': int(total_predictions),\n",
        "    'total_ground_truth': int(total_ground_truth),\n",
        "    'avg_precision_at_10': float(avg_precision_at_10),\n",
        "    'avg_recall': float(avg_recall),\n",
        "    'avg_f1_score': float(avg_f1),\n",
        "    'avg_hits_per_clip': float(avg_hits_per_clip),\n",
        "    'overall_precision': float(overall_precision),\n",
        "    'overall_recall': float(overall_recall),\n",
        "    'overall_f1_score': float(overall_f1),\n",
        "    'hits_distribution': convert_numpy_types(hits_distribution)\n",
        "}\n",
        "\n",
        "# Save detailed results\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump({\n",
        "        'summary': summary,\n",
        "        'detailed_results': json_safe_results\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(f\"Results saved to {output_file}\")\n",
        "\n",
        "# Also save summary only\n",
        "summary_file = 'eval/clap_baseline_summary.json'\n",
        "with open(summary_file, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(f\"Summary saved to {summary_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "clap",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
