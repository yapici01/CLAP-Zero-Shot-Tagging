{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Results Analysis: CLAP Approaches Comparison\n",
    "\n",
    "This notebook provides a manual review interface for comparing different CLAP-based approaches:\n",
    "- **Baseline CLAP**: Zero-shot predictions\n",
    "- **CLAP DF**: Document frequency weighted predictions  \n",
    "- **CLAP DF + SBERT**: DF weighted with semantic similarity\n",
    "\n",
    "We'll randomly sample 50 sounds and display their predictions alongside embedded audio players for manual evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:02:22.996416Z",
     "iopub.status.busy": "2025-06-19T18:02:22.996165Z",
     "iopub.status.idle": "2025-06-19T18:02:23.299844Z",
     "shell.execute_reply": "2025-06-19T18:02:23.299416Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import display, HTML, IFrame\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:02:23.301366Z",
     "iopub.status.busy": "2025-06-19T18:02:23.301237Z",
     "iopub.status.idle": "2025-06-19T18:02:23.303414Z",
     "shell.execute_reply": "2025-06-19T18:02:23.303189Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_sound_player(sound_id):\n",
    "    \"\"\"Displays an embedded player for a given Freesound sound ID.\"\"\"\n",
    "    # Create a clickable link to Freesound\n",
    "    freesound_url = f'https://freesound.org/people/sounds/{sound_id}/'\n",
    "    embed_url = f'https://freesound.org/embed/sound/iframe/{sound_id}/simple/medium/'\n",
    "    \n",
    "    # Display both a clickable link and embedded player\n",
    "    display(HTML(f'''\n",
    "    <div style=\"margin: 10px 0;\">\n",
    "        <p><strong>Listen:</strong> <a href=\"{freesound_url}\" target=\"_blank\">Open in Freesound</a></p>\n",
    "        <iframe src=\"{embed_url}\" width=\"696\" height=\"100\" frameborder=\"0\" scrolling=\"no\"></iframe>\n",
    "    </div>\n",
    "    '''))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:02:23.304498Z",
     "iopub.status.busy": "2025-06-19T18:02:23.304403Z",
     "iopub.status.idle": "2025-06-19T18:02:23.309058Z",
     "shell.execute_reply": "2025-06-19T18:02:23.308748Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load ground truth data\n",
    "print(\"Loading ground truth data...\")\n",
    "with open('data/input_ground_truth_pairs.json', 'r') as f:\n",
    "    ground_truth_data = json.load(f)\n",
    "\n",
    "# Create a mapping from sound_id to ground truth info\n",
    "gt_lookup = {item['sound_id']: item for item in ground_truth_data}\n",
    "print(f\"Loaded {len(gt_lookup)} ground truth entries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:02:23.325708Z",
     "iopub.status.busy": "2025-06-19T18:02:23.325579Z",
     "iopub.status.idle": "2025-06-19T18:02:23.360493Z",
     "shell.execute_reply": "2025-06-19T18:02:23.360191Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load prediction results\n",
    "print(\"Loading prediction results...\")\n",
    "\n",
    "# CLAP Baseline\n",
    "with open('eval/clap_baseline_results.json', 'r') as f:\n",
    "    clap_baseline_data = json.load(f)\n",
    "clap_baseline_lookup = {item['sound_id']: item for item in clap_baseline_data['detailed_results']}\n",
    "\n",
    "# CLAP DF\n",
    "with open('eval/clap_baseline_df_alpha0.7_results.json', 'r') as f:\n",
    "    clap_df_data = json.load(f)\n",
    "clap_df_lookup = {item['sound_id']: item for item in clap_df_data['detailed_results']}\n",
    "\n",
    "# CLAP DF + SBERT\n",
    "with open('eval/clap_baseline_df_sbert_alpha0.7_threshold0.7_results.json', 'r') as f:\n",
    "    clap_sbert_data = json.load(f)\n",
    "clap_sbert_lookup = {item['sound_id']: item for item in clap_sbert_data['detailed_results']}\n",
    "\n",
    "print(f\"Loaded CLAP Baseline: {len(clap_baseline_lookup)} results\")\n",
    "print(f\"Loaded CLAP DF: {len(clap_df_lookup)} results\")\n",
    "print(f\"Loaded CLAP DF+SBERT: {len(clap_sbert_lookup)} results\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Select Random Sample for Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:02:23.361795Z",
     "iopub.status.busy": "2025-06-19T18:02:23.361699Z",
     "iopub.status.idle": "2025-06-19T18:02:23.364456Z",
     "shell.execute_reply": "2025-06-19T18:02:23.364204Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find sound IDs that have results in all approaches\n",
    "all_sound_ids = set(gt_lookup.keys())\n",
    "sound_ids_with_all_results = (\n",
    "    all_sound_ids &\n",
    "    set(clap_baseline_lookup.keys()) &\n",
    "    set(clap_df_lookup.keys()) &\n",
    "    set(clap_sbert_lookup.keys())\n",
    ")\n",
    "\n",
    "print(f\"Total sounds with all results: {len(sound_ids_with_all_results)}\")\n",
    "\n",
    "# Randomly sample 50 sounds\n",
    "sample_size = min(50, len(sound_ids_with_all_results))\n",
    "sampled_sound_ids = random.sample(list(sound_ids_with_all_results), sample_size)\n",
    "\n",
    "print(f\"Selected {len(sampled_sound_ids)} sounds for analysis\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Analysis Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:02:23.365668Z",
     "iopub.status.busy": "2025-06-19T18:02:23.365593Z",
     "iopub.status.idle": "2025-06-19T18:02:23.370031Z",
     "shell.execute_reply": "2025-06-19T18:02:23.369808Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_tags_with_hits(predicted_tags: List[str], ground_truth_tags: List[str], hits: List[str]) -> str:\n",
    "    \"\"\"Format predicted tags with hits highlighted in bold.\"\"\"\n",
    "    formatted = []\n",
    "    for tag in predicted_tags:\n",
    "        if tag in hits:\n",
    "            formatted.append(f\"**{tag}**\")\n",
    "        else:\n",
    "            formatted.append(tag)\n",
    "    return \", \".join(formatted)\n",
    "\n",
    "def get_semantic_hits(predicted_tags: List[str], ground_truth_tags: List[str], semantic_hits: List[str]) -> List[str]:\n",
    "    \"\"\"Extract semantic hits that are not exact hits.\"\"\"\n",
    "    exact_hits = set(predicted_tags) & set(ground_truth_tags)\n",
    "    return [hit for hit in semantic_hits if hit not in exact_hits]\n",
    "\n",
    "def analyze_sound(sound_id: int) -> Dict:\n",
    "    \"\"\"Analyze a single sound across all CLAP approaches.\"\"\"\n",
    "    gt_info = gt_lookup[sound_id]\n",
    "    clap_baseline = clap_baseline_lookup[sound_id]\n",
    "    clap_df = clap_df_lookup[sound_id]\n",
    "    clap_sbert = clap_sbert_lookup[sound_id]\n",
    "    \n",
    "    # Get semantic-only hits for SBERT approach\n",
    "    sbert_semantic_only = get_semantic_hits(\n",
    "        clap_sbert['predicted_tags'], \n",
    "        clap_sbert['ground_truth_tags'], \n",
    "        clap_sbert.get('semantic_hits', [])\n",
    "    )\n",
    "    \n",
    "    # For CLAP SBERT, combine exact hits and semantic hits for total hits display\n",
    "    # The exact_hits is what we should compare to other approaches' hits\n",
    "    sbert_all_hits = clap_sbert.get('exact_hits', []) + clap_sbert.get('semantic_hits', [])\n",
    "    \n",
    "    return {\n",
    "        'sound_id': sound_id,\n",
    "        'title': gt_info['title'],\n",
    "        'input_tags': gt_info['input_tags'],\n",
    "        'ground_truth': gt_info['ground_truth_tags'],\n",
    "        'approaches': {\n",
    "            'CLAP Baseline': {\n",
    "                'predictions': clap_baseline['predicted_tags'][:10],\n",
    "                'hits': clap_baseline['hits'],\n",
    "                'num_hits': clap_baseline['num_hits'],\n",
    "                'precision': clap_baseline['precision_at_10'],\n",
    "                'recall': clap_baseline['recall'],\n",
    "                'f1': clap_baseline['f1_score']\n",
    "            },\n",
    "            'CLAP DF': {\n",
    "                'predictions': clap_df['predicted_tags'][:10],\n",
    "                'hits': clap_df['hits'],\n",
    "                'num_hits': clap_df['num_hits'],\n",
    "                'precision': clap_df['precision_at_10'],\n",
    "                'recall': clap_df['recall'],\n",
    "                'f1': clap_df['f1_score']\n",
    "            },\n",
    "            'CLAP DF+SBERT': {\n",
    "                'predictions': clap_sbert['predicted_tags'][:10],\n",
    "                'hits': clap_sbert.get('exact_hits', []),  # Use exact_hits for consistency\n",
    "                'semantic_hits': sbert_semantic_only,\n",
    "                'all_hits': sbert_all_hits,  # Include both exact and semantic\n",
    "                'num_hits': clap_sbert.get('num_exact_hits', 0),\n",
    "                'num_semantic_hits': clap_sbert.get('num_semantic_hits', 0),\n",
    "                'precision': clap_sbert['precision_at_10'],\n",
    "                'recall': clap_sbert['recall'],\n",
    "                'f1': clap_sbert['f1_score']\n",
    "            }\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Manual Review Interface\n",
    "\n",
    "The following cells will display each sampled sound with:\n",
    "- Audio player\n",
    "- Ground truth tags\n",
    "- Predictions from each approach with hits highlighted\n",
    "- Performance metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:02:23.371122Z",
     "iopub.status.busy": "2025-06-19T18:02:23.371035Z",
     "iopub.status.idle": "2025-06-19T18:02:23.373435Z",
     "shell.execute_reply": "2025-06-19T18:02:23.373176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze all sampled sounds \n",
    "print(\"Analyzing sampled sounds...\")\n",
    "analysis_results = []\n",
    "for sound_id in sampled_sound_ids:\n",
    "    try:\n",
    "        result = analyze_sound(sound_id)\n",
    "        analysis_results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing sound {sound_id}: {type(e).__name__}: {e}\")\n",
    "\n",
    "print(f\"Successfully analyzed {len(analysis_results)} sounds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:02:23.374715Z",
     "iopub.status.busy": "2025-06-19T18:02:23.374630Z",
     "iopub.status.idle": "2025-06-19T18:02:23.405562Z",
     "shell.execute_reply": "2025-06-19T18:02:23.405157Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display results for manual review\n",
    "for i, result in enumerate(analysis_results):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SOUND {i+1}/{len(analysis_results)}: {result['sound_id']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"\\n**Title:** {result['title']}\")\n",
    "    print(f\"**Input Tags:** {', '.join(result['input_tags'])}\")\n",
    "    print(f\"**Ground Truth:** {', '.join(result['ground_truth'])}\")\n",
    "    \n",
    "    # Audio player\n",
    "    print(f\"\\n**Audio Player:**\")\n",
    "    show_sound_player(result['sound_id'])\n",
    "    \n",
    "    # Results table\n",
    "    print(f\"\\n**Results Comparison:**\")\n",
    "    \n",
    "    # Display predictions for each approach in a readable format\n",
    "    for approach_name, approach_data in result['approaches'].items():\n",
    "        print(f\"\\n**{approach_name}:**\")\n",
    "        predictions_formatted = format_tags_with_hits(\n",
    "            approach_data['predictions'], \n",
    "            result['ground_truth'], \n",
    "            approach_data['hits']\n",
    "        )\n",
    "        print(f\"  Predictions: {predictions_formatted}\")\n",
    "        print(f\"  Hits: {len(approach_data['hits'])}, Precision@10: {approach_data['precision']:.3f}, Recall: {approach_data['recall']:.3f}, F1: {approach_data['f1']:.3f}\")\n",
    "    \n",
    "    # Add separator\n",
    "    if i < len(analysis_results) - 1:\n",
    "        print(f\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Summary Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T18:02:23.414239Z",
     "iopub.status.busy": "2025-06-19T18:02:23.414104Z",
     "iopub.status.idle": "2025-06-19T18:02:23.423006Z",
     "shell.execute_reply": "2025-06-19T18:02:23.422780Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate summary statistics for the sample\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS FOR SAMPLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_stats = {}\n",
    "approach_names = ['CLAP Baseline', 'CLAP DF', 'CLAP DF+SBERT']\n",
    "\n",
    "for approach in approach_names:\n",
    "    hits = [len(result['approaches'][approach]['hits']) for result in analysis_results]\n",
    "    precisions = [result['approaches'][approach]['precision'] for result in analysis_results]\n",
    "    recalls = [result['approaches'][approach]['recall'] for result in analysis_results]\n",
    "    f1s = [result['approaches'][approach]['f1'] for result in analysis_results]\n",
    "    \n",
    "    summary_stats[approach] = {\n",
    "        'avg_hits': np.mean(hits),\n",
    "        'avg_precision': np.mean(precisions),\n",
    "        'avg_recall': np.mean(recalls),\n",
    "        'avg_f1': np.mean(f1s),\n",
    "        'total_hits': sum(hits)\n",
    "    }\n",
    "\n",
    "# Display summary\n",
    "summary_df = pd.DataFrame(summary_stats).T\n",
    "summary_df = summary_df.round(3)\n",
    "summary_df.columns = ['Avg Hits/Sound', 'Avg Precision@10', 'Avg Recall', 'Avg F1', 'Total Hits']\n",
    "\n",
    "print(f\"\\nSample size: {len(analysis_results)} sounds\")\n",
    "display(summary_df)\n",
    "\n",
    "# Best performing approach\n",
    "best_f1 = summary_df['Avg F1'].max()\n",
    "best_approach = summary_df[summary_df['Avg F1'] == best_f1].index[0]\n",
    "print(f\"\\nBest performing approach by F1: {best_approach} (F1: {best_f1:.3f})\")\n",
    "\n",
    "best_hits = summary_df['Total Hits'].max()\n",
    "best_hits_approach = summary_df[summary_df['Total Hits'] == best_hits].index[0]\n",
    "print(f\"Most hits overall: {best_hits_approach} ({int(best_hits)} hits)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
